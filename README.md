# Pipeline de Dados: Combinando Python e Orientação a Objeto

🚀 Sobre o Projeto

Este projeto foi desenvolvido para resolver um desafio real de integração de dados resultante da fusão de duas grandes empresas. Cada empresa possuía bases de dados diferentes, armazenadas em formatos distintos (JSON e CSV). O objetivo principal era unificar essas fontes de dados e disponibilizá-las para o time de Business Intelligence (BI).

🎯 Objetivo do Projeto

Aplicar os principais fundamentos da Engenharia de Dados através da construção de um pipeline de ETL (Extração, Transformação e Carga). Além disso, o pipeline foi desenvolvido para ser reutilizável, permitindo a adaptação para outras necessidades de integração de dados no futuro.

⚠ Nota: Neste projeto, não explorei as principais ferramentas de Big Data. O foco foi na construção do pipeline utilizando Python e Programação Orientada a Objetos (POO).

🔨 Tecnologias Utilizadas

Python

Jupyter Notebook (exploração inicial)

VSCode (desenvolvimento final do pipeline)

JSON e CSV (manipulação de arquivos)

Programação Orientada a Objetos (POO)

🔍 Experiência Adquirida

✅ Criação de um pipeline de dados para integrar informações de empresas que passaram por um processo de fusão.✅ Manipulação de múltiplos formatos de dados (JSON e CSV) para unificação dos dados.✅ Exploração inicial no Jupyter Notebook, aplicando conceitos fundamentais de Python, como:

Laços de repetição (for)

Condicionais (if)

Bibliotecas para manipulação de arquivos (json, csv)
✅ Refatoração do código para um script mais eficiente no VSCode, organizando a estrutura em funções e aplicando POO.✅ Criação de uma classe específica para representar o pipeline, tornando-o reutilizável e modular.

🔎 Próximos Passos

Melhorar a escalabilidade do pipeline.

Implementar ferramentas de Big Data para processar grandes volumes de informações.

Criar testes automatizados para garantir a qualidade do pipeline.

📌 Este projeto faz parte do meu portfólio. Feedbacks são bem-vindos! 😃


